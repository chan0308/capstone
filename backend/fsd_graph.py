# backend/fsd_graph.py
from __future__ import annotations

from typing import Any, Dict, List, Optional, TypedDict, Annotated
import json
import textwrap

from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_core.messages import (
    BaseMessage,
    HumanMessage,
    SystemMessage,
    AIMessage,
)

# Llama (Ollama)
from langchain_community.chat_models import ChatOllama

from fsd_tools import analyze_market_sentiment


# ------------------------------------------------------------
# 0. ê³µí†µ ìœ í‹¸
# ------------------------------------------------------------

def get_llm(model: str = "llama3.1", temperature: float = 0.1):
    """
    Llama ê¸°ë°˜ ì±—ëª¨ë¸ ìƒì„±.
    """
    return ChatOllama(model=model, temperature=temperature)


def safe_json_loads(text: str) -> Dict[str, Any]:
    """
    LLMì´ ì¤€ ë¬¸ìì—´ì„ ìµœëŒ€í•œ JSONìœ¼ë¡œ íŒŒì‹±í•˜ê¸° ìœ„í•œ ìœ í‹¸.
    JSON ë¸”ë¡ë§Œ ì˜ë¼ì„œ ë¡œë”© ì‹œë„.
    """
    text = text.strip()
    # ```json ... ``` ê°ì‹¸ì ¸ ìˆì„ ê°€ëŠ¥ì„±
    if text.startswith("```"):
        text = text.strip("`")
        parts = text.split("\n", 1)
        if parts and parts[0].lower().startswith("json"):
            text = parts[1] if len(parts) > 1 else ""

    # ì¤‘ê´„í˜¸ ê¸°ì¤€ìœ¼ë¡œ ì•ë’¤ ìë¥´ê¸°
    first = text.find("{")
    last = text.rfind("}")
    if first != -1 and last != -1 and last > first:
        text = text[first : last + 1]

    return json.loads(text)


# ------------------------------------------------------------
# 1. í‚¤ì›Œë“œ / íƒ€ì… ì •ì˜
# ------------------------------------------------------------

TESLA_KEYWORD_CANDIDATES: List[str] = [
    "tesla", "musk", "fsd", "autopilot", "robotaxi", "cybercab",
    "self-driving", "autonomous driving", "driverless",
    "safety", "crash", "collision", "recall", "investigation",
    "nhtsa", "dmv", "cpuc", "disengagement", "permit", "ride-hailing",
    "í…ŒìŠ¬ë¼", "ììœ¨ì£¼í–‰", "ë¡œë´‡íƒì‹œ", "ì•ˆì „", "ì‚¬ê³ ", "ì¶©ëŒ",
    "ë¦¬ì½œ", "ì¡°ì‚¬", "í—ˆê°€", "ìº˜ë¦¬í¬ë‹ˆì•„",
]


class SentimentRow(TypedDict):
    topic: str
    score: float
    sentiment: str  # "Negative" | "Mixed" | "Neutral" | "Positive"


# í”„ë¡ íŠ¸ ì´ˆê¸°ê°’ê³¼ ë™ì¼í•œ ì°¨íŠ¸ ê¸°ë³¸ê°’
DEFAULT_SENTIMENT_CHART: List[SentimentRow] = [
    {"topic": "Safety",    "score": -0.42, "sentiment": "Negative"},
    {"topic": "Recall",    "score": -0.38, "sentiment": "Negative"},
    {"topic": "Collision", "score": -0.28, "sentiment": "Negative"},
    {"topic": "Autopilot", "score": -0.15, "sentiment": "Mixed"},
    {"topic": "Quality",   "score":  0.05, "sentiment": "Neutral"},
]


class ChatState(TypedDict):
    """
    LangGraph state êµ¬ì¡°.
    - messages: ëŒ€í™” íˆìŠ¤í† ë¦¬
    - tool_request: LLMì´ ë§Œë“  íˆ´ í˜¸ì¶œ ê³„íš
    - tool_result: í¬ë¡¤ë§/ê°ì„±ë¶„ì„ ê²°ê³¼
    """
    messages: Annotated[List[BaseMessage], add_messages]
    tool_request: Optional[Dict[str, Any]]
    tool_result: Optional[Dict[str, Any]]


# ------------------------------------------------------------
# 2. ì‹¤ì œë¡œ ì‹¤í–‰ë  "íˆ´" â€“ í¬ë¡¤ë§ + ê°ì„±ë¶„ì„ + LDA
# ------------------------------------------------------------

def crawl_market_sentiment(
    question: str,
    selected_keywords: List[str],
    llm,  # LangGraphì—ì„œ ì“°ëŠ” LLM ì¸ìŠ¤í„´ìŠ¤ (ì˜ˆ: ChatOllama)
) -> Dict[str, Any]:
    ...
    lda_block = "\n".join(lda_lines) if lda_lines else "(no clear LDA topics)"

    # ğŸ”½ ì—¬ê¸°ë¶€í„° í”„ë¡¬í”„íŠ¸ë¥¼ í•œêµ­ì–´ ë²„ì „ìœ¼ë¡œ êµì²´
    prompt = f"""
ë„ˆëŠ” í…ŒìŠ¬ë¼ FSD(Full Self-Driving)/ë¡œë³´íƒì‹œì— ëŒ€í•œ
ì‹œì¥ ì¸ì‹ê³¼ ì•ˆì „ ì´ìŠˆë¥¼ ë¶„ì„í•˜ëŠ” ë¦¬ì„œì¹˜ ë³´ì¡°ì›ì´ë‹¤.

[ì‚¬ìš©ì ì§ˆë¬¸]
{question}

[ìˆ˜ì§‘í•œ ë°ì´í„° ê°œìˆ˜]
ì „ì²´ ë¬¸ì„œ ìˆ˜: ì•½ {raw_count}ê±´

[ê²€ìƒ‰ì— ì‚¬ìš©í•œ í‚¤ì›Œë“œ]
{", ".join(selected_keywords)}

[í† í”½ë³„ ê°ì„± ì ìˆ˜ (-1 ~ +1)]
{topic_block}

[LDA í† í”½ í´ëŸ¬ìŠ¤í„°(ìƒìœ„ í‚¤ì›Œë“œ)]
{lda_block}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ** ë‹µë³€í•˜ë¼.

ìš”êµ¬ì‚¬í•­:
1) Safety, Recall, Collision, Autopilot, Quality ê°ê°ì— ëŒ€í•´
   í˜„ì¬ ì‹œì¥ ì¸ì‹ì´ ì–´ë–¤ì§€ í•œ ì¤„ì”© ìš”ì•½í•˜ë¼.
2) ê°€ì¥ ë¶€ì •ì ì¸ ë¦¬ìŠ¤í¬ 2~3ê°€ì§€ë¥¼ bulletë¡œ ì •ë¦¬í•˜ë¼.
3) ê·¸ë‚˜ë§ˆ ê¸ì •ì ì¸ ì‹ í˜¸ 2~3ê°€ì§€ë¥¼ bulletë¡œ ì •ë¦¬í•˜ë¼.
4) ì „ì²´ ë¶„ìœ„ê¸°ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬í•˜ëŠ” ê²°ë¡ ì„ ì¨ë¼.

í˜•ì‹:
- bullet point ìœ„ì£¼ë¡œ 4~6ì¤„ ì •ë„ì˜ ê°„ê²°í•œ ìš”ì•½
- ê³¼ë„í•œ ìˆ˜ì‹ì–´ëŠ” í”¼í•˜ê³ , ë¶„ì„ì ì¸ í†¤ì„ ìœ ì§€í•  ê²ƒ
"""

    llm_answer = llm.invoke(prompt).content

    return {
        "answer": llm_answer,
        "sentiment_chart": sentiment_chart,
        "lda_topics": lda_topics,
    }


TOOLS = {
    "crawl_market_sentiment": crawl_market_sentiment,
}


# ------------------------------------------------------------
# 3. LangGraph ë…¸ë“œ ì •ì˜
# ------------------------------------------------------------

def planner_node(state: ChatState, llm) -> Dict[str, Any]:
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³´ê³ ,
    - ì–´ë–¤ ë„êµ¬ë¥¼ ì“¸ì§€
    - ì–´ë–¤ í‚¤ì›Œë“œë¥¼ ë„˜ê¸¸ì§€
    ë¥¼ JSONìœ¼ë¡œ ê³„íší•˜ëŠ” ë…¸ë“œ.
    """
    system_prompt = textwrap.dedent(
        f"""
        ë„ˆëŠ” í…ŒìŠ¬ë¼/FSD/ììœ¨ì£¼í–‰ ê´€ë ¨ ì‹œì¥ ì¸ì‹ê³¼ ì•ˆì „ ì´ìŠˆë¥¼ ì¡°ì‚¬í•˜ëŠ”
        ë¦¬ì„œì¹˜ ë³´ì¡°ì›ì´ë‹¤.

        ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë„êµ¬ëŠ” í•˜ë‚˜ë‹¤:

        1) "crawl_market_sentiment"
           - ì„¤ëª…: í…ŒìŠ¬ë¼ ë° ììœ¨ì£¼í–‰ ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ Reddit/ë‰´ìŠ¤ì—ì„œ
                   ê²Œì‹œê¸€ì„ ìˆ˜ì§‘í•˜ê³ , ë¶€ì •/ì¤‘ë¦½/ê¸ì • ê°ì„± ë° LDA í† í”½ì„ ë¶„ì„í•œë‹¤.
           - íŒŒë¼ë¯¸í„°:
             â€¢ query: ì‚¬ìš©ìì˜ ì›ë˜ ì§ˆë¬¸ (string)
             â€¢ keywords: ê²€ìƒ‰ì— ì‚¬ìš©í•  ìƒìœ„ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (string ë°°ì—´, ìµœëŒ€ 5ê°œ)

        í‚¤ì›Œë“œ í›„ë³´ëŠ” ì•„ë˜ ë¦¬ìŠ¤íŠ¸ì—ì„œë§Œ ê³ ë¥¸ë‹¤.
        ê° ì§ˆë¬¸ë§ˆë‹¤, ì´ ì¤‘ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ìƒìœ„ 3~5ê°œë¥¼ ì„ íƒí•´ë¼.

        í›„ë³´ í‚¤ì›Œë“œ:
        {", ".join(TESLA_KEYWORD_CANDIDATES)}

        ì¶œë ¥ í˜•ì‹(ë°˜ë“œì‹œ JSONë§Œ, ì„¤ëª… ì—†ì´):

        {{
          "name": "crawl_market_sentiment",
          "parameters": {{
            "query": "ì‚¬ìš©ì ì§ˆë¬¸ ê·¸ëŒ€ë¡œ",
            "keywords": ["tesla", "fsd", "safety", ...]
          }}
        }}
        """
    ).strip()

    messages: List[BaseMessage] = [
        SystemMessage(content=system_prompt),
        *state["messages"],
    ]

    ai: AIMessage = llm.invoke(messages)
    tool_request = safe_json_loads(ai.content)

    return {
        "messages": [ai],
        "tool_request": tool_request,
    }


def run_tool_node(state: ChatState, llm) -> Dict[str, Any]:
    """
    planner_nodeê°€ ë§Œë“  tool_requestë¥¼ ì‹¤ì œ Python í•¨ìˆ˜(íˆ´)ì— ì—°ê²°.
    """
    req = state.get("tool_request") or {}
    name = req.get("name")
    params = req.get("parameters") or {}

    if not name or name not in TOOLS:
        # íˆ´ì„ ëª» ê³¨ëê±°ë‚˜, ì´ìƒí•œ ì´ë¦„ì´ë©´ ê·¸ëƒ¥ ì•„ë¬´ê²ƒë„ ì•ˆ í•¨
        return {
            "tool_result": {
                "analysis_summary": "ë„êµ¬ í˜¸ì¶œ ê³„íšì„ ë§Œë“¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
                "sentiment_chart": DEFAULT_SENTIMENT_CHART,
                "lda_topics": [],
            }
        }

    tool_fn = TOOLS[name]
    try:
        if name == "crawl_market_sentiment":
            # plannerì—ì„œ ë§Œë“  query/keywordsë¥¼ ìš°ë¦¬ í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ì— ë§ê²Œ ë§¤í•‘
            question = params.get("query", "")
            keywords = params.get("keywords", [])
            result = tool_fn(question=question, selected_keywords=keywords, llm=llm)
        else:
            # (í˜¹ì‹œ ë‚˜ì¤‘ì— ë‹¤ë¥¸ íˆ´ ëŠ˜ì–´ë‚˜ë©´)
            result = tool_fn(**params)
    except Exception as e:
        result = {
            "analysis_summary": f"íˆ´ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}",
            "sentiment_chart": DEFAULT_SENTIMENT_CHART,
            "lda_topics": [],
        }

    return {"tool_result": result}


# ------------------------------------------------------------
# 4. ê·¸ë˜í”„ ì»´íŒŒì¼ + ì™¸ë¶€ì—ì„œ ì“¸ helper í•¨ìˆ˜
# ------------------------------------------------------------

def _build_graph():
    llm = get_llm()

    builder = StateGraph(ChatState)
    builder.add_node("planner", lambda s, _llm=llm: planner_node(s, _llm))
    builder.add_node("run_tool", lambda s, _llm=llm: run_tool_node(s, _llm))

    builder.add_edge(START, "planner")
    builder.add_edge("planner", "run_tool")
    builder.add_edge("run_tool", END)

    return builder.compile()


_graph = _build_graph()


def run_fsd_agent(user_message: str) -> Dict[str, Any]:
    """
    FastAPIì—ì„œ ì“°ê¸° ì¢‹ì€ í—¬í¼.
    ì¸í’‹: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
    ì•„ì›ƒí’‹: {
      "answer": str,
      "sentiment_chart": List[SentimentRow],
      "raw_tool_result": Dict[str, Any]
    }
    """
    initial_state: ChatState = {
        "messages": [HumanMessage(content=user_message)],
        "tool_request": None,
        "tool_result": None,
    }

    final_state: ChatState = _graph.invoke(initial_state)
    tool_result = final_state.get("tool_result") or {}

    # ì •ìƒ ê²½ë¡œ: crawl_market_sentiment ê°€ ë§Œë“¤ì–´ì¤€ answer ì‚¬ìš©
    answer = (
        tool_result.get("answer")
        or tool_result.get("analysis_summary")
        or "ë¶„ì„ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    )
    sentiment_chart = tool_result.get("sentiment_chart", DEFAULT_SENTIMENT_CHART)

    return {
        "answer": answer,
        "sentiment_chart": sentiment_chart,
        "raw_tool_result": tool_result,
    }
